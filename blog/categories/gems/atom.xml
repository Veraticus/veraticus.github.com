<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: gems | Hi, I'm Josh Symonds]]></title>
  <link href="http://joshsymonds.com/blog/categories/gems/atom.xml" rel="self"/>
  <link href="http://joshsymonds.com/"/>
  <updated>2012-10-11T02:10:22-05:00</updated>
  <id>http://joshsymonds.com/</id>
  <author>
    <name><![CDATA[Josh Symonds]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Dynamoid 0.4.0]]></title>
    <link href="http://joshsymonds.com/blog/2012/05/01/dynamoid-0-dot-4-0/"/>
    <updated>2012-05-01T00:04:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/05/01/dynamoid-0-dot-4-0</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/Veraticus/Dynamoid">Dynamoid 0.4.0</a> is a pretty significant improvement over previous iterations of Dynamoid. While the project has obviously always been my hobby, 0.4.0 represents what I would consider one of the first iterations I would use in a real production application. Not because the previous version haven't worked -- they've all done exactly what they should do. But now it has the flexibility and options to really allow an application to thrive in Amazon's DynamoDB.</p>

<p>What do I mean by that?</p>

<!-- more -->


<h3>Per-table Performance</h3>

<p>Previously to 0.4.0, Dynamoid's table provisioning relied on the defaults that Dynamoid provided (100 read, 20 write) and then manual tuning if you wanted to make any changes from there. And that's for every table. This was especially frustrating because you can only scale up to twice the current value (though you can do that as many times as you want)... but the real downer is you can only scale down 20%, and you can only do that once per day. So obviously if my defaults didn't work for you, you had to go through a couple of days of readjustment, and who wants that?</p>

<p>Now you can specify performance options for each table you create, using the new <code>table</code> Dynamoid syntax:</p>

<p>```ruby
class Tweet
  include Dynamoid::Document</p>

<p>  table name: :twitters, key: :tweet_id, read_capacity: 200, write_capacity: 200
end
```</p>

<p>As a bonus you can also change the hash key and even the table name. Though the table name will still be placed in your namespace -- so if your namespace is <code>dynamoid</code>, your table will be <code>dynamoid_twitters</code>, in the above example.</p>

<h3>Consistent Querying</h3>

<p>Consistency in enormous databases can be a troublesome question to address. I've read <a href="http://nosql.mypopescu.com/post/18844539755/why-dynamodb-consistent-reads-cost-twice-or-whats">that DynamoDB's consistent pricing</a> is too high and I agree with Alex's points: but we live in a universe where DynamoDB consistent reading is reality, so we may as well make the best of it.</p>

<p>That said, thanks to <a href="https://github.com/ananthakumaran">Anantha Kumaran</a>, Dynamoid can now take full advantage of DynamoDB's consistent read feature. Issuing queries like this:</p>

<p><code>ruby
Address.where(:city =&gt; 'Chicago').consistent.all
Address.find(1, :consistent =&gt; true)
</code></p>

<p>Will retrieve all results, even the most recently-written ones. I gotta say, having people you don't even know commit to projects is one of the joys of open source programming, and this feature was written entirely by Anantha (though refactored a bit by yours truly).</p>

<h3>Future Functionality</h3>

<p>I had a suggestion from <a href="http://twitter.com/aaronnamba">Aaron Namba</a> to implement a rake task that would create tables. I think that's a great idea; expanding on it, a task to reprovision existing tables would also be pretty cool. Also, Mongoid offers embedded relations -- it should be no problem to offer those in DynamoDB through Dynamoid as well. The only issue, of course, is indexing the children IDs from inside their parents... but we already perform indexing, so it wouldn't be that bad.</p>

<p>Speaking of indexing, being able to index an association attribute would be pretty keen. So then you could go <code>user.addresses.where(:city =&gt; 'Chicago').all</code> and have it perform a quick lookup on a denormalized index table, rather than manually find all addresses for the user and then use Ruby to filter them. I'm not sure about this functionality, though, for the same reason that I'm unsure about adding geolocation.</p>

<p>Geolocation, you say? Yes indeed. Initially I had specced out a <a href="http://en.wikipedia.org/wiki/Geohash">geohash-style</a> geolocation functionality that would allow models to do single-field location and distance finding. The longer I pondered the problem, though, the less compelling this answer seemed to me. Amazing pieces of software have already been developed (like <a href="http://www.elasticsearch.org/">elasticsearch</a>) that are dedicated only to indexing (both text and geolocation). They do it faster and easier than DynamoDB probably ever could, and even Amazon has acknowledged this with the creation of their <a href="http://aws.amazon.com/cloudsearch/">CloudSearch</a> service.</p>

<p>So I'm not sure complicated indexing will ever be on the table for Dynamoid. DynamoDB has some strengths and some really glaring weakness; and one of those weaknesses is indexing. Denormalized data is a pain to manage, and even though Dynamoid takes care of it all for you behind the scenes, complicated index tables make your application difficult to understand and painful to manage.</p>

<p>Unless I hear compelling arguments otherwise, I'll probably be relying on elasticsearch for my future Dynamoid applications. But the two of them should go together like peanut butter and chocolate; I'm working on a project now that should make significant use of both of them, so look for a future blog post detailing the two of them working together!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Middleman for Non-Techies]]></title>
    <link href="http://joshsymonds.com/blog/2012/04/21/middleman-for-non-techies/"/>
    <updated>2012-04-21T11:56:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/04/21/middleman-for-non-techies</id>
    <content type="html"><![CDATA[<p>I didn't make a post on the 18th because I've been in San Francisco at <a href="http://www.refinery29.com/hipstamatic-office-pictures">the Hipstamatic offices</a>, which are totally awesome. The work I've been doing here has taken up all of my time, so I didn't even get the chance to start writing a post until today. While I was here, I met <a href="http://lukesbeard.com/">Luke Beard</a>, a super talented designer who's been touching up a lot of our sites. For example, the excellent <a href="http://disposable.hipstamatic.com/">disposable.hipstamatic.com</a> site is all his handiwork. I wanted to streamline his development process, so that he could deploy his work without feeling blocked by my (usually extremely full) schedule.</p>

<p>We're going to use <a href="https://github.com/middleman/middleman">Middleman</a> to achieve this, in addition to some other nice effects: automatic minification of JS and CSS and smushing of images. Middleman is essentially intended for developers, though; it requires commandline tools that can be fairly intimidating to those who've never really bothered popping open the console before. So here's some small tweaks I made to our HTML projects to make the whole process easier on Luke and any future designers we hire.</p>

<!-- more -->


<h2>Use Middleman 3</h2>

<p>Luke doesn't use CoffeeScript or Sass (yet), so the CSS files he creates are just pure CSS. In Middleman 2, .css files aren't automatically minified unless they're run through a secondary processor, like Scss or Compass. This was extremely frustrating to figure out, but is happily really easy to fix. Use Middleman 3. Middleman 3 is in beta and you can install it like so:</p>

<p><code>bash
gem install middleman --pre
</code></p>

<p>The Middleman 3 beta has a number of <a href="http://awardwinningfjords.com/2012/01/03/middleman-3-beta.html">other cool features</a> that are worth checking out. In my limited experience using it, there aren't any major syntax changes; my Middleman 2 projects converted without a single hitch.</p>

<h2>Circumvent the Console</h2>

<p>Once people figure out git, they universally love it. Most of our non-technical people who've been introduced to it use <a href="http://mac.github.com/">Github for Mac</a>, though, because honestly the console commands are kind of arcane. Half way through an explanation of the syntax of <code>git add</code>, I realized I was really barking up the wrong tree. So I didn't want to force people to open a console window, cd into the Middleman directory, and start up a server. As simple as that sounds, I knew it would be an enormous point of failure.</p>

<p>So I made a quick little script I inserted into the Middleman project directories.</p>

<p>```ruby</p>

<h1>!/usr/bin/env ruby</h1>

<p>Kernel.exec("cd #{File.dirname(<strong>FILE</strong>)} &amp;&amp; middleman")
```</p>

<p>I called it <code>start</code>. Chmod it 0755, and then when the designer checks out the repository, they can just double-click on <code>start</code> to automatically boot up the middleman console.</p>

<h2>Deploy with Hubot</h2>

<p>Of course, we also wanted to make it easy to deploy. My deploy script is stolen entirely from a <a href="https://gist.github.com/1902178">gist</a>:</p>

<p>```ruby
SSH_USER = 'root'
SSH_HOST = 'www.example.com'
SSH_DIR  = '/var/www/html/www.example.com'</p>

<p>desc "Build the website from source"
task :build do
  puts "## Building website"
  status = system("middleman build --clean")
  puts status ? "OK" : "FAILED"
end</p>

<p>desc "Run the preview server at http://localhost:4567"
task :preview do
  system("middleman server")
end</p>

<p>desc "Deploy website via rsync"
task :deploy do
  puts "## Deploying website via rsync to #{SSH_HOST}"
  status = system("rsync -avze 'ssh' --delete build/ #{SSH_USER}@#{SSH_HOST}:#{SSH_DIR}")
  puts status ? "OK" : "FAILED"
end</p>

<p>desc "Build and deploy website"
task :gen_deploy => [:build, :deploy] do
end
```</p>

<p>Actually executing this script requires the console, and see the point I made just above for how I feel about that. Instead, we decided that our resident <a href="http://hubot.github.com/">hubot</a> (named Hipstabot of course) should be the one to deploy the actual code. We already use him to deploy our Rails site, and typing commands in a Campfire chatroom is a lot easier and more sensible than typing commands into the commandline. This is a sanitized version of the CoffeeScript I wrote to allow Hipstabot to deploy static sites:</p>

<p>```coffeescript
module.exports = (robot) ->
  robot.respond /deploy site (\w*)/i, (msg) -></p>

<pre><code>util = require('util')
exec = require('child_process').exec

site = msg.match[1]

msg.send "[#{site}/deploy] Initiating deploy"
exec "cd /home/hipstabot/workspace/#{site} &amp;&amp; sudo -u hipstabot git pull", (error, stdout, stderr) -&gt;
  if error != null
    msg.send "Fatal error pulling repository:"
    msg.send chomp stderr
  else
    msg.send "[#{site}/deploy] Building &amp; deploying site"
    exec "cd /home/hipstabot/workspace/#{site} &amp;&amp; sudo -u hipstabot rake gen_deploy", (error, stdout, stderr) -&gt;
      if error != null
        msg.send "Fatal error building site:"
        msg.send chomp stderr
      else
        msg.send "[#{site}/deploy] Deploy complete"
</code></pre>

<p>chomp = (text) ->
  text.replace(/(\n|\r)+$/, '')
```</p>

<p>All the sudoing is to ensure no weirdness happens with directories being owned by someone other than Hipstabot, which would prevent git from pulling correctly.</p>

<p>Using this process, Luke can deploy sites quickly and easily, our customers get minified CSS and JS, and I'm not involved in any step of the process. Creating workflows like this -- that make what people do easier and better -- is one of the greatest joys of being a programmer, and I hope someone finds this post helpful in accomplishing something similar.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Elasticsearch in Rails with Tire]]></title>
    <link href="http://joshsymonds.com/blog/2012/04/15/testing-elasticsearch-in-rails-with-tire/"/>
    <updated>2012-04-15T23:38:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/04/15/testing-elasticsearch-in-rails-with-tire</id>
    <content type="html"><![CDATA[<p>In my <a href="http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails/">previous entry on elasticsearch</a>, I promised I would elaborate on testing <a href="http://www.elasticsearch.org/">elasticsearch</a> (and <a href="https://github.com/karmi/tire">tire</a>) in Rails applications. There's not really a whole lot of secret sauce to it, but I figured it'd make a good, quick post with some crunchy code for a late night. While writing, though, I realized I could also talk about a small problem I ran into while using tire -- specifically relating to index regeneration. This isn't a major flaw, but it did waste some of my time, so I figured documenting it (prior to fixing it) would be a sensible idea.</p>

<!-- more -->


<h2>Testing Tire</h2>

<p>There are two components to testing tire: the first is emptying the index before tests where the contents of the index matters, and the second is ensuring that you only delete the index you want, rather than your development index (which would be annoying). Deleting the correct index is really easy. You just want something like this in your model:</p>

<p>```ruby
class Photo
  include Tire::Model::Search</p>

<p>  index_name("#{Rails.env}-search-photos")</p>

<p>  ...
end
```</p>

<p>Specifying <code>index_name</code> as dependent on the Rails environment ensures that your development index won't be destroyed by the next bit of code.</p>

<p><code>ruby
def clear_photo_index
  Photo.tire.index.delete
  Photo.tire.index.create(:mappings =&gt; Photo.tire.mapping_to_hash, :settings =&gt; Photo.tire.settings)
  Photo.tire.index.refresh
end
</code></p>

<p>I stuck that code in <code>test_helper.rb</code> and I call it before each of my photo tests. The first line, obviously, deletes the entire index. The second recreates it, using the mappings and settings already specified in the Photo model. And then we refresh it just to make sure that tire agrees with elasticsearch about the indexed fields.</p>

<h2>Caveat Indexor</h2>

<p>Overall, tire and elasticsearch have been joys to use. I have experienced unexpected behavior in tire though, particularly relating to index mappings. Obviously, deleting an index in tire works just as expected -- the index and all its associated data goes away. Also deleted are the field mappings for that index. However, what happens when you try to create a new object without reloading the class that defined it?</p>

<p>Tire still faithfully stores the object into the deleted index. This invokes elasticsearch's <a href="http://www.elasticsearch.org/guide/reference/api/index_.html">automatic index creation</a> logic, which attempts to determine the types of your fields manually. Unfortunately, it never seems to correctly identify geo_point fields properly. For example, this is what my index mapping should look like:</p>

<p><code>ruby
{"photo"=&gt;{"properties"=&gt;{"account_id"=&gt;{"type"=&gt;"string"}, "id"=&gt;{"type"=&gt;"string"}, "lat_lng"=&gt;{"type"=&gt;"geo_point"}, "name"=&gt;{"type"=&gt;"string", "analyzer"=&gt;"snowball"}}}}
</code></p>

<p>But if I delete the index and then insert an object into it, elasticsearch automatically determines the types as follows:</p>

<p><code>ruby
{"photo"=&gt;{"properties"=&gt;{"_type"=&gt;{"type"=&gt;"string"}, "account_id"=&gt;{"type"=&gt;"long"}, "id"=&gt;{"type"=&gt;"long"}, "lat_lng"=&gt;{"type"=&gt;"string"}, "name"=&gt;{"type"=&gt;"string"}}}}
</code></p>

<p>The key difference here is that <code>lat_lng</code> is not a geo_point but is instead a string, which prevents any of the index geolocation queries from being run on it. You can correct this problem by deleting the index and reloading the class in which the index is defined, which causes tire to create the index again from your provided mapping. (Or run the <code>tire.index.create</code> code from above.) But I spent a tiring(pun!) hour trying to figure out why my indexes kept on receiving inappropriate field types before hitting on this as the reason.</p>

<p>Similarly, and possibly more frustratingly, if you are incrementally developing an index, changes to your mapping won't appear in the index until you delete said index and reload its defining class. Again, deleting the index and inserting data immediately will cause elasticsearch to guess the field mappings for your index, with tragically inconsistent results.</p>

<p>I told the very talented <a href="https://github.com/karmi">karmi</a> about this problem and he sensibly suggested I write a failing test for it, though unfortunately I haven't had the time to sit down and really do that. In the meantime, just know that this annoyance exists, and if you're working on tire indexes, make sure you religiously delete the mapping and then reload the class before you attempt to use the index again.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch and Percolation in Rails]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails/"/>
    <updated>2012-03-25T11:39:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails</id>
    <content type="html"><![CDATA[<p>Hipstamatic uses the pretty awesome Family Album feature for people to like and react to each others' photos. You can create either a magic album -- an album that matches to a combination of criteria including accounts, geolocation, tags and descriptions -- or a curated album, selecting photos directly that you want to include. The latter is a pretty straight-forward association and isn't very interesting to talk about, but I wanted to discuss briefly the methods we used to implement magic albums and what we finally settled on. It involved a lot of setting up elasticsearch and percolation, and ultimately I think it's a very durable, excellent solution for anyone wanting to index a lot of data and retrieve it extremely quickly.</p>

<!-- more -->


<p>Initially, magic albums were a set of complicated MySQL queries. I think anyone who's had experience with indexes in an enormous MySQL database knows where this one is going... its performance was terrible, and as more people created more albums our RDS instance started really chugging. The worst part was we were spending enormous amounts of time, energy, and money invested in a small part of our application, and it was having a cascade effect through the database ruining the rest of the user experience.</p>

<p>As a stopgap measure, we switched to using Redis lists to hold the association but kept the actual index in MySQL. Recently though we migrated away from MySQL completely to an index storage called <a href="http://www.elasticsearch.org/">elasticsearch</a>. Elasticsearch is awesome because it's built on Lucene, is incredibly easy to get going, and is very very powerful. I passed over search solutions like <a href="http://sphinxsearch.com/">Sphinx</a> and <a href="http://www.searchify.com/">Searchify</a> mostly because we aren't doing any text searching: all of the queries albums perform on photos are controlled by direct, matched fields. We just needed a great, simple engine for indexing them constantly and pulling results out quickly -- an engine that wouldn't bring the rest of our stack down if there was an indexing failure or if we were bombarded with many simultaneous queries.</p>

<p>Elasticsearch has given us all that and more. Using the amazing <a href="https://github.com/karmi/tire">tire</a> gem, it was simple to get our photo model set up correctly:</p>

<p>```ruby
class Photo &lt; ActiveRecord::Base
  include Tire::Model::Search</p>

<p>  mapping do</p>

<pre><code>indexes :id
indexes :lat_lng, :type =&gt; :geo_point
indexes :account_id
indexes :created_at, :type =&gt; :date
indexes :tags
</code></pre>

<p>  end
end
```</p>

<p>(The code here is changed slightly from its production form to redact business logic and simplify it.) Of course, the real magic takes place in the albums model. Albums are essentially saved queries, if you think about it: they should search for photos every time they're called. So we have a method to generate the query we're looking for:</p>

<p>```ruby
class Album &lt; ActiveRecord::Base</p>

<p>  def elasticsearch_query</p>

<pre><code>query = []
query &lt;&lt; {:terms =&gt; {:account_ids =&gt; query[:accounts]}} unless query[:accounts].blank?
query &lt;&lt; {:terms =&gt; {:tags =&gt; query[:tags]}} unless query[:tags].blank?
query &lt;&lt; {:range =&gt; {:created_at =&gt; {:from =&gt; query[:starts_at], :to =&gt; query[:ends_at]}}} unless query[:starts_at].blank? &amp;&amp; query[:ends_at].blank?
query &lt;&lt; {:geo_distance =&gt; {:lat_lng =&gt; [query[:lat].to_f, query[:lng].to_f.join(','), :distance =&gt; "#{query[:range]}km"}} unless query[:lat].blank? || query[:lng].blank?
query
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>These are all, in elasticsearch parlance, filters rather than queries: queries must look into data fields and perform operations in them, whereas filters just filter on a fields' value directly... exactly what I was looking for. <code>terms</code> instructs the filter parser that at least one of the select elements must match. <code>range</code>, as you can see, allows us to pull only photos within a certain date. <code>geo_distance</code> is particularly cool and lets us filter all photos by their geographic location.</p>

<p>Using this couldn't be simpler:</p>

<p>```ruby
class Album &lt; ActiveRecord::Base</p>

<p>  def elasticsearch_photos</p>

<pre><code>finder = Photo.search do
  query { all }
  filter(:and, elasticsearch_query) unless elasticsearch_query.empty?
  sort {by :created_at, "desc" }
end

finder.results
</code></pre>

<p>  end
```</p>

<p>Tada! Easy and simple searching inside your models. The performance gain for us was massive; elasticsearch has a ridiculously small memory footprint, but consistently returns responses to us in 50-60 milliseconds. Now that's performance!</p>

<p>Many of you might be wondering, though, how we get the reverse of this association. Albums have many (searched) photos; how does a photo know what album it's in? This was a stumbling block for the other search solutions I investigated, and I was concerned I would have to bust out the old, gimpy MySQL.</p>

<p>But elasticsearch to the rescue! It employs a very neat feature called <a href="http://www.elasticsearch.org/blog/2011/02/08/percolator.html">the percolator</a>. Percolation allows us to save searches as an index themselves, and then determine what objects match any of the saved searches. So, we save the search an album would conduct along with the album's ID into the photo percolator; then we can determine what queries a photo matches when we save it. It's really quite ingenuous and was, of course, ridiculously easy to set up:</p>

<p>```
class Album &lt; ActiveRecord::Base
  after_save :register_query</p>

<p>  def register_query</p>

<pre><code>Photo.index.register_percolator_query(self.id) do |q|
  q.filtered do
    query {all}
    filter(:and, elasticsearch_query) unless elasticsearch_query.empty?
  end
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>This uses the same <code>elasticsearch_query</code> method as above (of course, since we want to save the same query into the database). And on the photo model, to use it, we just do:</p>

<p>```
class Photo &lt; ActiveRecord::Base</p>

<p>  def percolated_albums</p>

<pre><code>Album.find(Photo.index.percolate(self))
</code></pre>

<p>  end
end
```</p>

<p>This was a rather whirlwind tour, but I was really impressed at how easy it was to get elasticsearch set up properly. It really has added quite a lot to our stack and I look forward to using it on other domain problems (maybe even including full text search)! It was pretty easy to get it tested as well, but I think I'll save details on how I did that for another post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why I Don't Use Haml]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/22/why-i-dont-use-haml/"/>
    <updated>2012-03-22T13:19:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/22/why-i-dont-use-haml</id>
    <content type="html"><![CDATA[<p>I initially thought of titling this post something more inflammatory, like "Why Haml Sucks" or "Only Losers Use Haml." But the truth is <a href="http://haml-lang.com/">Haml</a> does anything but suck. It's actually quite elegant; the syntax is clean, not needing closing tags is just really cool, and it's very fast to read. It seems like it would be an ideal language to replace HTML, just like SASS and CoffeeScript are abstractions of and (to a certain extent) replacements for CSS and JavaScript, respectively.</p>

<p>So why do I bang my head against my desk every time I see someone using it in a view?</p>

<!-- more -->


<h2>Indentation Sucks (Usually)</h2>

<p>Notice the cute little parenthetical up there? That's because I really do like CoffeeScript, which is just as whitespace-sensitive as Haml. So what's the difference?</p>

<p>CoffeeScript uses indentations to abstract away one of the worst "features" of JavaScript: the dreaded <code>})</code> sequences. Closing arguments and functions again and again is not only a headache, it happens so frequently that some sort of error is inevitable. Strict whitespace rules help us avoid errors in closure. Of course, the same argument can be made about HTML and Haml's whitespace rules, but there's another key difference here.</p>

<p>HTML closures indicate which tag they close. You don't have a forest of <code>)})})}</code>, which even if you indent correctly still won't tell you which parenthesis or bracket they're closing. Instead you have an obvious and syntactic declaration of which tag you're ending when you end it. You can argue that the tag closure is unnecessary (Haml seems largely based on this argument), but you're trading explicit tag closure for explicit whitespace restrictions...</p>

<p>And ultimately (and most damningly), whitespace restrictions make the document harder to read and understand than closing tags. If you have an extremely long page with many nested elements, Haml is very difficult to comprehend and consequently much harder to use.</p>

<h2>If It Ain't Broke...</h2>

<p>SASS and CoffeeScript fix serious errors and oversights in the implementations of their specific languages. CoffeeScript ensures correct lexical scoping of variables; SASS allows variable assignment and better selectors than CSS. Both are enormous improvements on the languages they compile into.</p>

<p>Haml doesn't add anything at all to HTML. There's no special Haml tags that do something HTML couldn't do by itself. It gives you a shortcut for the syntax, but that's essentially it.</p>

<p>And HTML really isn't that bad by itself. The syntax is already fairly clean and clear; it's not like we're lost in a field of, well, parenthesis and curly brackets. Tables can get a little muddy at times, but good HTML and CSS prevent documents from becoming unreadable -- and Haml doesn't offer any interesting or unique tools to improve readability, either.</p>

<h2>Designers Aren't Programmers</h2>

<p>But I think this is the biggest reason I don't use Haml. Frontend designers use CSS, and the best ones employ JavaScript (and program good JavaScript!) -- but every single one is going to be using HTML to create their pages. Eventually, if your site gets big, you're going to want a designer to do some pages for you... and they're not going to be producing Haml, they're going to be producing HTML.</p>

<p>Sure, you can change that HTML to Haml. But let me guarantee you, one day they'll want to change something, and at that point you do one of three things:</p>

<ol>
<li>Show them the Haml site, tell them to do it all in Haml, and pay for them learning it.</li>
<li>Take their design and convert it to Haml yourself and then incorporate it into the page.</li>
<li>Curse your unjust fate and just switch to erb and copypaste their changes in.</li>
</ol>


<p>As I said at the beginning, I like Haml. But it's a markup language for programmers, and ultimately the people who use HTML the most aren't programmers. SASS is barely a programming language, more like a set of syntactical shortcuts; and CoffeeScript appeals to those who program in JavaScript already. Haml just doesn't appeal to the correct audience to use its core feature set, which is a damn shame, because Haml really is pretty cool.</p>
]]></content>
  </entry>
  
</feed>
