<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: gems | Hi, I'm Josh Symonds]]></title>
  <link href="http://joshsymonds.com/blog/categories/gems/atom.xml" rel="self"/>
  <link href="http://joshsymonds.com/"/>
  <updated>2013-02-04T18:06:39-06:00</updated>
  <id>http://joshsymonds.com/</id>
  <author>
    <name><![CDATA[Josh Symonds]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Huey Gem Release]]></title>
    <link href="http://joshsymonds.com/blog/2012/12/21/huey-gem-release/"/>
    <updated>2012-12-21T01:53:00-06:00</updated>
    <id>http://joshsymonds.com/blog/2012/12/21/huey-gem-release</id>
    <content type="html"><![CDATA[<p>I pushed the first version of <a href="https://github.com/Veraticus/huey">Huey</a> to <a href="http://rubygems.org/gems/huey">RubyGems</a> (calling it 0.1.0).</p>

<p>It's in a really good state right now, actually -- in addition to a rather full and complete set of tests, I added a couple neat new features:</p>

<ul>
<li><p>Now you can make as many changes as you like to a bulb, and then commit them all at once with <code>save</code> (alias as <code>commit</code> for your convenience).</p></li>
<li><p>Ability to set colors as a RGB hex. So you can do <code>bulb.rgb  = '#8FF1F5'</code> to get your bulb to be colored aqua. Colors in Hue are a little more pastel than you might expect, though, so exact shade matching might take a bit of experimentation.</p></li>
<li><p>Copyright and license information.</p></li>
</ul>


<p>I'll be adding more features as I use it more, so watch <a href="https://github.com/Veraticus/huey">the repository</a> for changes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Huey, for Controlling Phillips Hue Lightbulbs]]></title>
    <link href="http://joshsymonds.com/blog/2012/11/28/huey-for-controlling-phillips-hue-lightbulbs/"/>
    <updated>2012-11-28T01:08:00-06:00</updated>
    <id>http://joshsymonds.com/blog/2012/11/28/huey-for-controlling-phillips-hue-lightbulbs</id>
    <content type="html"><![CDATA[<p>I just authored a cool little Gem that allows for automatic discovery of, and control over, the pretty nifty <a href="http://meethue.com">Phillips Hue lightbulbs</a>. I decided to name it <a href="https://github.com/Veraticus/huey">Huey</a>, since I love nothing more than cute and silly names. I only spent a few hours tonight hacking it together, so I'm sure there's a lot of room for improvement, but it works and does everything it's supposed to and seems fairly fault tolerant; so I thought, why not announce it and fix problems when I wake up tomorrow?</p>

<!-- more -->


<p>Huey uses <a href="http://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> to discover the IP of the Hue hub the first time the code is run. I wish I could take credit for the EventMachine code that went into making this work correctly, but actually I largely cribbed it from Turboladen's <a href="https://github.com/turboladen/upnp">upnp library</a>. I would've just included it as a Gem dependency but for some reason it's not released as a Gem, which is pretty frustrating for situations like this.</p>

<p>I chose a pretty boring UUID for Huey to use: <code>'0123456789abdcef0123456789abcdef'</code>. This works just fine, but if you want to change it Huey is ultra-configurable and you can do so either in a block or directly:</p>

<p>```ruby
  Huey.configure do |config|</p>

<pre><code>config.uuid = '0123456789abdcef0123456789abcdef'
</code></pre>

<p>  end
  # or
  Huey::Config.uuid = '0123456789abdcef0123456789abcdef'
```</p>

<p>The first time you issue a request to the Hue hub, you'll likely see an attractive error message like this:</p>

<p><code>ruby
  Huey::Errors::PressLinkButton: 'Press the link button and try your request again'
</code></p>

<p>Unfortunately, the first time any request is sent, Hue needs to validate the new client by you actually walking over and touching the link button on the hub. But once you do that, you can just resend the request and it should work fine. Then you can use the whole gamut of the Hue API:</p>

<p>```ruby
Huey::Bulb.all # Returns an array of your bulbs</p>

<p>bulb = Huey::Bulb.find(1) # Finds the bulb with the ID of 1
bulb = Huey::Bulb.find('Living Room') # Finds the bulb with the name 'Living Room'</p>

<p>bulb.alert! # Flashes the bulb in question once, useful for checking connectivity
bulb.on = false # Turn the bulb off
bulb.bri = 100 # Dim the bulb a little bit
bulb.ct = 500 # Change the bulb's color
```</p>

<p>I think Huey is pretty cool and I definitely intend to make a lot of use out of it. I'll be updating it constantly as I do so to support more and better features, so follow the repository and let me know what you think.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dynamoid 0.4.0]]></title>
    <link href="http://joshsymonds.com/blog/2012/05/01/dynamoid-0-dot-4-0/"/>
    <updated>2012-05-01T00:04:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/05/01/dynamoid-0-dot-4-0</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/Veraticus/Dynamoid">Dynamoid 0.4.0</a> is a pretty significant improvement over previous iterations of Dynamoid. While the project has obviously always been my hobby, 0.4.0 represents what I would consider one of the first iterations I would use in a real production application. Not because the previous version haven't worked -- they've all done exactly what they should do. But now it has the flexibility and options to really allow an application to thrive in Amazon's DynamoDB.</p>

<p>What do I mean by that?</p>

<!-- more -->


<h3>Per-table Performance</h3>

<p>Previously to 0.4.0, Dynamoid's table provisioning relied on the defaults that Dynamoid provided (100 read, 20 write) and then manual tuning if you wanted to make any changes from there. And that's for every table. This was especially frustrating because you can only scale up to twice the current value (though you can do that as many times as you want)... but the real downer is you can only scale down 20%, and you can only do that once per day. So obviously if my defaults didn't work for you, you had to go through a couple of days of readjustment, and who wants that?</p>

<p>Now you can specify performance options for each table you create, using the new <code>table</code> Dynamoid syntax:</p>

<p>```ruby
class Tweet
  include Dynamoid::Document</p>

<p>  table name: :twitters, key: :tweet_id, read_capacity: 200, write_capacity: 200
end
```</p>

<p>As a bonus you can also change the hash key and even the table name. Though the table name will still be placed in your namespace -- so if your namespace is <code>dynamoid</code>, your table will be <code>dynamoid_twitters</code>, in the above example.</p>

<h3>Consistent Querying</h3>

<p>Consistency in enormous databases can be a troublesome question to address. I've read <a href="http://nosql.mypopescu.com/post/18844539755/why-dynamodb-consistent-reads-cost-twice-or-whats">that DynamoDB's consistent pricing</a> is too high and I agree with Alex's points: but we live in a universe where DynamoDB consistent reading is reality, so we may as well make the best of it.</p>

<p>That said, thanks to <a href="https://github.com/ananthakumaran">Anantha Kumaran</a>, Dynamoid can now take full advantage of DynamoDB's consistent read feature. Issuing queries like this:</p>

<p><code>ruby
Address.where(:city =&gt; 'Chicago').consistent.all
Address.find(1, :consistent =&gt; true)
</code></p>

<p>Will retrieve all results, even the most recently-written ones. I gotta say, having people you don't even know commit to projects is one of the joys of open source programming, and this feature was written entirely by Anantha (though refactored a bit by yours truly).</p>

<h3>Future Functionality</h3>

<p>I had a suggestion from <a href="http://twitter.com/aaronnamba">Aaron Namba</a> to implement a rake task that would create tables. I think that's a great idea; expanding on it, a task to reprovision existing tables would also be pretty cool. Also, Mongoid offers embedded relations -- it should be no problem to offer those in DynamoDB through Dynamoid as well. The only issue, of course, is indexing the children IDs from inside their parents... but we already perform indexing, so it wouldn't be that bad.</p>

<p>Speaking of indexing, being able to index an association attribute would be pretty keen. So then you could go <code>user.addresses.where(:city =&gt; 'Chicago').all</code> and have it perform a quick lookup on a denormalized index table, rather than manually find all addresses for the user and then use Ruby to filter them. I'm not sure about this functionality, though, for the same reason that I'm unsure about adding geolocation.</p>

<p>Geolocation, you say? Yes indeed. Initially I had specced out a <a href="http://en.wikipedia.org/wiki/Geohash">geohash-style</a> geolocation functionality that would allow models to do single-field location and distance finding. The longer I pondered the problem, though, the less compelling this answer seemed to me. Amazing pieces of software have already been developed (like <a href="http://www.elasticsearch.org/">elasticsearch</a>) that are dedicated only to indexing (both text and geolocation). They do it faster and easier than DynamoDB probably ever could, and even Amazon has acknowledged this with the creation of their <a href="http://aws.amazon.com/cloudsearch/">CloudSearch</a> service.</p>

<p>So I'm not sure complicated indexing will ever be on the table for Dynamoid. DynamoDB has some strengths and some really glaring weakness; and one of those weaknesses is indexing. Denormalized data is a pain to manage, and even though Dynamoid takes care of it all for you behind the scenes, complicated index tables make your application difficult to understand and painful to manage.</p>

<p>Unless I hear compelling arguments otherwise, I'll probably be relying on elasticsearch for my future Dynamoid applications. But the two of them should go together like peanut butter and chocolate; I'm working on a project now that should make significant use of both of them, so look for a future blog post detailing the two of them working together!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Middleman for Non-Techies]]></title>
    <link href="http://joshsymonds.com/blog/2012/04/21/middleman-for-non-techies/"/>
    <updated>2012-04-21T11:56:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/04/21/middleman-for-non-techies</id>
    <content type="html"><![CDATA[<p>I didn't make a post on the 18th because I've been in San Francisco at <a href="http://www.refinery29.com/hipstamatic-office-pictures">the Hipstamatic offices</a>, which are totally awesome. The work I've been doing here has taken up all of my time, so I didn't even get the chance to start writing a post until today. While I was here, I met <a href="http://lukesbeard.com/">Luke Beard</a>, a super talented designer who's been touching up a lot of our sites. For example, the excellent <a href="http://disposable.hipstamatic.com/">disposable.hipstamatic.com</a> site is all his handiwork. I wanted to streamline his development process, so that he could deploy his work without feeling blocked by my (usually extremely full) schedule.</p>

<p>We're going to use <a href="https://github.com/middleman/middleman">Middleman</a> to achieve this, in addition to some other nice effects: automatic minification of JS and CSS and smushing of images. Middleman is essentially intended for developers, though; it requires commandline tools that can be fairly intimidating to those who've never really bothered popping open the console before. So here's some small tweaks I made to our HTML projects to make the whole process easier on Luke and any future designers we hire.</p>

<!-- more -->


<h2>Use Middleman 3</h2>

<p>Luke doesn't use CoffeeScript or Sass (yet), so the CSS files he creates are just pure CSS. In Middleman 2, .css files aren't automatically minified unless they're run through a secondary processor, like Scss or Compass. This was extremely frustrating to figure out, but is happily really easy to fix. Use Middleman 3. Middleman 3 is in beta and you can install it like so:</p>

<p><code>bash
gem install middleman --pre
</code></p>

<p>The Middleman 3 beta has a number of <a href="http://awardwinningfjords.com/2012/01/03/middleman-3-beta.html">other cool features</a> that are worth checking out. In my limited experience using it, there aren't any major syntax changes; my Middleman 2 projects converted without a single hitch.</p>

<h2>Circumvent the Console</h2>

<p>Once people figure out git, they universally love it. Most of our non-technical people who've been introduced to it use <a href="http://mac.github.com/">Github for Mac</a>, though, because honestly the console commands are kind of arcane. Half way through an explanation of the syntax of <code>git add</code>, I realized I was really barking up the wrong tree. So I didn't want to force people to open a console window, cd into the Middleman directory, and start up a server. As simple as that sounds, I knew it would be an enormous point of failure.</p>

<p>So I made a quick little script I inserted into the Middleman project directories.</p>

<p>```ruby</p>

<h1>!/usr/bin/env ruby</h1>

<p>Kernel.exec("cd #{File.dirname(<strong>FILE</strong>)} &amp;&amp; middleman")
```</p>

<p>I called it <code>start</code>. Chmod it 0755, and then when the designer checks out the repository, they can just double-click on <code>start</code> to automatically boot up the middleman console.</p>

<h2>Deploy with Hubot</h2>

<p>Of course, we also wanted to make it easy to deploy. My deploy script is stolen entirely from a <a href="https://gist.github.com/1902178">gist</a>:</p>

<p>```ruby
SSH_USER = 'root'
SSH_HOST = 'www.example.com'
SSH_DIR  = '/var/www/html/www.example.com'</p>

<p>desc "Build the website from source"
task :build do
  puts "## Building website"
  status = system("middleman build --clean")
  puts status ? "OK" : "FAILED"
end</p>

<p>desc "Run the preview server at http://localhost:4567"
task :preview do
  system("middleman server")
end</p>

<p>desc "Deploy website via rsync"
task :deploy do
  puts "## Deploying website via rsync to #{SSH_HOST}"
  status = system("rsync -avze 'ssh' --delete build/ #{SSH_USER}@#{SSH_HOST}:#{SSH_DIR}")
  puts status ? "OK" : "FAILED"
end</p>

<p>desc "Build and deploy website"
task :gen_deploy => [:build, :deploy] do
end
```</p>

<p>Actually executing this script requires the console, and see the point I made just above for how I feel about that. Instead, we decided that our resident <a href="http://hubot.github.com/">hubot</a> (named Hipstabot of course) should be the one to deploy the actual code. We already use him to deploy our Rails site, and typing commands in a Campfire chatroom is a lot easier and more sensible than typing commands into the commandline. This is a sanitized version of the CoffeeScript I wrote to allow Hipstabot to deploy static sites:</p>

<p>```coffeescript
module.exports = (robot) ->
  robot.respond /deploy site (\w*)/i, (msg) -></p>

<pre><code>util = require('util')
exec = require('child_process').exec

site = msg.match[1]

msg.send "[#{site}/deploy] Initiating deploy"
exec "cd /home/hipstabot/workspace/#{site} &amp;&amp; sudo -u hipstabot git pull", (error, stdout, stderr) -&gt;
  if error != null
    msg.send "Fatal error pulling repository:"
    msg.send chomp stderr
  else
    msg.send "[#{site}/deploy] Building &amp; deploying site"
    exec "cd /home/hipstabot/workspace/#{site} &amp;&amp; sudo -u hipstabot rake gen_deploy", (error, stdout, stderr) -&gt;
      if error != null
        msg.send "Fatal error building site:"
        msg.send chomp stderr
      else
        msg.send "[#{site}/deploy] Deploy complete"
</code></pre>

<p>chomp = (text) ->
  text.replace(/(\n|\r)+$/, '')
```</p>

<p>All the sudoing is to ensure no weirdness happens with directories being owned by someone other than Hipstabot, which would prevent git from pulling correctly.</p>

<p>Using this process, Luke can deploy sites quickly and easily, our customers get minified CSS and JS, and I'm not involved in any step of the process. Creating workflows like this -- that make what people do easier and better -- is one of the greatest joys of being a programmer, and I hope someone finds this post helpful in accomplishing something similar.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Elasticsearch in Rails with Tire]]></title>
    <link href="http://joshsymonds.com/blog/2012/04/15/testing-elasticsearch-in-rails-with-tire/"/>
    <updated>2012-04-15T23:38:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/04/15/testing-elasticsearch-in-rails-with-tire</id>
    <content type="html"><![CDATA[<p>In my <a href="http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails/">previous entry on elasticsearch</a>, I promised I would elaborate on testing <a href="http://www.elasticsearch.org/">elasticsearch</a> (and <a href="https://github.com/karmi/tire">tire</a>) in Rails applications. There's not really a whole lot of secret sauce to it, but I figured it'd make a good, quick post with some crunchy code for a late night. While writing, though, I realized I could also talk about a small problem I ran into while using tire -- specifically relating to index regeneration. This isn't a major flaw, but it did waste some of my time, so I figured documenting it (prior to fixing it) would be a sensible idea.</p>

<!-- more -->


<h2>Testing Tire</h2>

<p>There are two components to testing tire: the first is emptying the index before tests where the contents of the index matters, and the second is ensuring that you only delete the index you want, rather than your development index (which would be annoying). Deleting the correct index is really easy. You just want something like this in your model:</p>

<p>```ruby
class Photo
  include Tire::Model::Search</p>

<p>  index_name("#{Rails.env}-search-photos")</p>

<p>  ...
end
```</p>

<p>Specifying <code>index_name</code> as dependent on the Rails environment ensures that your development index won't be destroyed by the next bit of code.</p>

<p><code>ruby
def clear_photo_index
  Photo.tire.index.delete
  Photo.tire.index.create(:mappings =&gt; Photo.tire.mapping_to_hash, :settings =&gt; Photo.tire.settings)
  Photo.tire.index.refresh
end
</code></p>

<p>I stuck that code in <code>test_helper.rb</code> and I call it before each of my photo tests. The first line, obviously, deletes the entire index. The second recreates it, using the mappings and settings already specified in the Photo model. And then we refresh it just to make sure that tire agrees with elasticsearch about the indexed fields.</p>

<h2>Caveat Indexor</h2>

<p>Overall, tire and elasticsearch have been joys to use. I have experienced unexpected behavior in tire though, particularly relating to index mappings. Obviously, deleting an index in tire works just as expected -- the index and all its associated data goes away. Also deleted are the field mappings for that index. However, what happens when you try to create a new object without reloading the class that defined it?</p>

<p>Tire still faithfully stores the object into the deleted index. This invokes elasticsearch's <a href="http://www.elasticsearch.org/guide/reference/api/index_.html">automatic index creation</a> logic, which attempts to determine the types of your fields manually. Unfortunately, it never seems to correctly identify geo_point fields properly. For example, this is what my index mapping should look like:</p>

<p><code>ruby
{"photo"=&gt;{"properties"=&gt;{"account_id"=&gt;{"type"=&gt;"string"}, "id"=&gt;{"type"=&gt;"string"}, "lat_lng"=&gt;{"type"=&gt;"geo_point"}, "name"=&gt;{"type"=&gt;"string", "analyzer"=&gt;"snowball"}}}}
</code></p>

<p>But if I delete the index and then insert an object into it, elasticsearch automatically determines the types as follows:</p>

<p><code>ruby
{"photo"=&gt;{"properties"=&gt;{"_type"=&gt;{"type"=&gt;"string"}, "account_id"=&gt;{"type"=&gt;"long"}, "id"=&gt;{"type"=&gt;"long"}, "lat_lng"=&gt;{"type"=&gt;"string"}, "name"=&gt;{"type"=&gt;"string"}}}}
</code></p>

<p>The key difference here is that <code>lat_lng</code> is not a geo_point but is instead a string, which prevents any of the index geolocation queries from being run on it. You can correct this problem by deleting the index and reloading the class in which the index is defined, which causes tire to create the index again from your provided mapping. (Or run the <code>tire.index.create</code> code from above.) But I spent a tiring(pun!) hour trying to figure out why my indexes kept on receiving inappropriate field types before hitting on this as the reason.</p>

<p>Similarly, and possibly more frustratingly, if you are incrementally developing an index, changes to your mapping won't appear in the index until you delete said index and reload its defining class. Again, deleting the index and inserting data immediately will cause elasticsearch to guess the field mappings for your index, with tragically inconsistent results.</p>

<p>I told the very talented <a href="https://github.com/karmi">karmi</a> about this problem and he sensibly suggested I write a failing test for it, though unfortunately I haven't had the time to sit down and really do that. In the meantime, just know that this annoyance exists, and if you're working on tire indexes, make sure you religiously delete the mapping and then reload the class before you attempt to use the index again.</p>
]]></content>
  </entry>
  
</feed>
