<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: servers | Hi, I'm Josh Symonds]]></title>
  <link href="http://joshsymonds.com/blog/categories/servers/atom.xml" rel="self"/>
  <link href="http://joshsymonds.com/"/>
  <updated>2014-07-29T15:01:37-05:00</updated>
  <id>http://joshsymonds.com/</id>
  <author>
    <name><![CDATA[Josh Symonds]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Getting Started With AWS OpsWorks]]></title>
    <link href="http://joshsymonds.com/blog/2014/06/11/getting-started-with-aws-opsworks/"/>
    <updated>2014-06-11T13:59:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2014/06/11/getting-started-with-aws-opsworks</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been creating a complicated OpsWorks server setup for a client, as I mentioned in <a href="http://joshsymonds.com/blog/2014/05/09/creating-an-aws-opsworks-instance-store-ami/">my last post</a>, and I&rsquo;ve been really enjoying the process. OpsWorks, while still a beta service, has a lot to recommend itself: it couples the best parts of chef to the power of the impressive AWS APIs. Using OpsWorks, it&rsquo;s easy to make processes that seem almost magical.</p>

<p>How magical? Well, imagine super-fast command line deploys, seamless cookbook updates, great chatbot and application integration, then marry all those things to AWS autoscaling via elastic load balancing. One use case for my client: <a href="https://travis-ci.org/">TravisCI</a> automatically creating servers, running remote acceptance tests on them, then destroying them afterwards &mdash; all while notifying chatrooms of its progress. Now that&rsquo;s assurance your code will work in production! Really, the sky&rsquo;s the limit here for awesome integrations.</p>

<p>I&rsquo;ve learned a lot in the process of implementing this setup. If you&rsquo;re looking to give OpsWorks a go for your next project, here&rsquo;s some hints and tips to make get started on the right path.</p>

<!-- more -->


<h2>1. Setup vagrant to be compatible with OpsWorks</h2>

<p>You&rsquo;ll want to test all of your OpsWorks recipes locally &mdash; how else can you be sure they&rsquo;ll work remotely? <a href="http://www.vagrantup.com/">Vagrant</a> is the ideal tool for making this happen. You&rsquo;ll want to download the same AMI and the same version of chef that OpsWorks is using: ubuntu 12.04 and chef 11.10 respectively, for me. Here&rsquo;s how to do that in your <code>Vagrantfile</code>:</p>

<p>```ruby
VAGRANTFILE_API_VERSION = &ldquo;2&rdquo;</p>

<p>Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = &ldquo;ubuntu-precise64&rdquo;
  config.vm.box_url = &ldquo;<a href="https://opscode-vm-bento.s3.amazonaws.com/vagrant/opscode_ubuntu-12.04_provisionerless.box">https://opscode-vm-bento.s3.amazonaws.com/vagrant/opscode_ubuntu-12.04_provisionerless.box</a>&rdquo;</p>

<p>  # Specifies the chef version Opsworks is running
  config.omnibus.chef_version = &ldquo;11.10.0&rdquo;
end
```</p>

<p>This requires the <code>vagrant-omnibus</code> plugin, which you can install with <code>vagrant plugin install vagrant-omnibus</code>.</p>

<h2>2. Use librarian-chef</h2>

<p>OpsWorks expects all of your recipes to be in one git repository that it can download. This may be bad practice for many chefs, but since it&rsquo;s required here and it&rsquo;s the cookbook repository format that <a href="https://github.com/applicationsonline/librarian-chef">librarian-chef</a> expects and supports, you&rsquo;ll want to download and configure librarian-chef.</p>

<p>Just the default librarian-chef configuration works, with one exception: you&rsquo;ll want to strip <code>.git</code> directories from the checked-out sources to prevent OpsWorks from becoming confused. That&rsquo;s relatively easy to set up:</p>

<p><code>bash
librarian-chef config install.strip-dot-git 1 --local
</code></p>

<p>I store the source of my cookbooks in one repository and use an orphan branch of that same repository for the actual cookbooks that are installed and managed by librarian. This is pretty easy to set up:</p>

<p>```bash</p>

<h1>Create the orphan branch</h1>

<p>git checkout &mdash;orphan cookbooks
git rm -rf .
git add . -A
git commit -m &lsquo;Initial commit&rsquo;
git push origin cookbooks
```</p>

<p>Then in your master branch, set up your cookbook branch as a submodule in a subdirectory that librarian-chef will install to:</p>

<p>```</p>

<h1>.gitmodules</h1>

<p>[submodule &ldquo;cookbooks&rdquo;]
  path = cookbooks
  url = git@github.com:user/repository.git
  branch = cookbooks
```</p>

<p>I have a small Rakefile that allows me to run <code>rake</code> to sync my changes directly to the cookbooks branch.</p>

<p>```ruby
desc &ldquo;install all cookbooks and synchronize them to GitHub&rdquo;
task :default do
  puts &ldquo;## Installing cookbooks&rdquo;
  system &ldquo;librarian-chef install&rdquo;
  puts &ldquo;## Pushing cookbooks to GitHub&rdquo;
  cd &ldquo;cookbooks&rdquo; do</p>

<pre><code>system %Q(echo "gitdir: ../.git/modules/cookbooks" &gt; .git)
system "git add ."
system "git add -u"
message = "Cookbooks generated via librarian-chef at #{Time.now.utc}"
system "git commit -m \"#{message}\""
system "git pull"
system "git push origin cookbooks"
</code></pre>

<p>  end
  puts &ldquo;## Done!&rdquo;
end
```</p>

<p>Keep in mind this setup isn&rsquo;t ideal for collaboration: if I had a lot of people updating the cookbooks simultaneously, I would definitely set up separate repositories. But for smaller OpsWorks projects, this works perfectly well.</p>

<h2>3. Don&rsquo;t bother with OpsWorks' recipe syntax</h2>

<p>Though it&rsquo;s clever that OpsWorks has their own recipe syntax they&rsquo;d like you to use, my advice is: don&rsquo;t. If you ever want to use your chef recipes somewhere else &mdash; or bring chef recipes from elsewhere to OpsWorks &mdash; you&rsquo;ll thank yourself for just using the standard recipe format. So instead of this:</p>

<p>```ruby</p>

<h1>No!</h1>

<p>node[:deploy].each do |app_name, deploy|
  template &lsquo;/etc/init/puma.conf&rsquo; do</p>

<pre><code>source 'puma.conf'
owner  'root'
group  'root'
mode   '0644'
</code></pre>

<p>  end
end
```</p>

<p>Use the plainer, simpler:</p>

<p>```ruby</p>

<h1>Yes!</h1>

<p>template &lsquo;/etc/init/puma.conf&rsquo; do
  source &lsquo;puma.conf&rsquo;
  owner  &lsquo;root&rsquo;
  group  &lsquo;root&rsquo;
  mode   &lsquo;0644&rsquo;
end
```</p>

<p>The former syntax won&rsquo;t work properly on vagrant, just for starters, which is a great reason all by itself not to use it. You&rsquo;ll want to control what recipes get applied where through custom layers rather than OpsWorks' special syntax.</p>

<h2>4. Overwrite any recipes that overlap</h2>

<p>OpsWorks inserts a lot of their own recipes into your cookbooks, and you can&rsquo;t disable this behavior, even if you&rsquo;re using your own custom recipes. This can lead to naming collisions that can be frustrating to resolve. For a Rails stack, I had to manually remove the <code>unicorn</code> and <code>passenger-apache2</code> cookbooks that led to merge errors with the <code>application_ruby</code> cookbook. Thankfully, removing cookbooks in OpsWorks is pretty easy: if you have a recipe named exactly the same as an OpsWorks one, yours will replace it.</p>

<p>You&rsquo;ll want to create a cookbook named after the offending cookbook (for example, <code>unicorn</code>) and replace every file in the OpsWorks cookbook with a blank one. You can find all the OpsWorks cookbook sources <a href="https://github.com/aws/opsworks-cookbooks">in their GitHub repository</a>. So, to continue the unicorn example, you&rsquo;d make a <code>unicorn</code> directory, a <code>recipes</code> subdirectory, and three files: <code>default</code>, <code>rails</code>, and <code>stop</code>. The content of all these files should be something like this:</p>

<p>```ruby</p>

<h1>Prevent OpsWorks from trying to install this cookbook.</h1>

<p>```</p>

<p>Obviously you should only do this if you&rsquo;re definitely not using OpsWorks' cookbooks.</p>

<h2>5. OpsWorks is your single point of truth</h2>

<p>Get rid of your data bags, encrypted data bags, configuration yaml files: everything. Embrace OpsWorks as your centralized chef server and the primary authority on the state and setup of your application. Data bags are arguably chef smell at this point anyway, and OpsWorks continues their inexorable slide towards obsolescence. You&rsquo;ll want to set up everything you can with sensible attributes in your custom application recipes:</p>

<p>```ruby</p>

<h1>site-cookbooks/your-app/attributes/default.rb</h1>

<p>default[&lsquo;database&rsquo;] = {
  &lsquo;pool&rsquo; => 5,
  &lsquo;host&rsquo; => &lsquo;localhost&rsquo;,
  &lsquo;name&rsquo; => &lsquo;app_database&rsquo;,
  &lsquo;username&rsquo; => &lsquo;username&rsquo;,
  &lsquo;password&rsquo; => &lsquo;password&rsquo;
}
```</p>

<p>Then pass overrides in your stack JSON. Your stack JSON is where you&rsquo;ll enumerate all the settings particular to your environment: though I&rsquo;m not incredibly happy with this setup, as it&rsquo;s not versioned, AWS makes it easy to copy stack and layer setups really easily, so in practice it&rsquo;s not difficult to update multiple stacks or create a new one from sensible defaults.</p>

<h2>6. Use the AWS API</h2>

<p>So what&rsquo;s the real advantage of doing this whole song and dance? Using the AWS API, you can command and control your servers (and all your attached AWS stuff) with an ease and simplicity you can&rsquo;t achieve anywhere else. But for more details on that, you&rsquo;ll just have to stay tuned for my next post, which will discuss all the awesome things you can start doing with OpsWorks once you have it set up properly.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating an AWS OpsWorks Instance Store AMI]]></title>
    <link href="http://joshsymonds.com/blog/2014/05/09/creating-an-aws-opsworks-instance-store-ami/"/>
    <updated>2014-05-09T13:00:45-05:00</updated>
    <id>http://joshsymonds.com/blog/2014/05/09/creating-an-aws-opsworks-instance-store-ami</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been doing a fair amount of work in Amazon&rsquo;s <a href="https://aws.amazon.com/opsworks/">OpsWorks</a>, in many ways an elegant service. Once you have a set of chef recipes provisioning properly, you&rsquo;ll want to create an AMI for the layer in question so that you don&rsquo;t have to wait through a long setup process again. Unfortunately, doing this in OpsWorks can be frustrating since the instructions for making it happen are scattered across <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html">four</a> <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami-instance-store.html">entirely</a> <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/ec2-cli-get-set-up.html#install-ami-tools">different</a> <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/set-up-ec2-cli-linux.html">documents</a>. For my own sanity I made a checklist of all the steps necessary to create an AMI on an instance store EC2 server: this is that checklist for anyone else who might find it useful.</p>

<!-- more -->


<h2>0. Get your chef recipes working in OpsWorks</h2>

<p>Don&rsquo;t do any of this until you have a fully-provisioned server working exactly as you&rsquo;d expect. Make sure <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-autohealing.html">auto healing</a> is disabled for the layer. The rest of the steps assume you have such a properly set-up instance, a well configured layer, and that the original image was Ubuntu 12.04.</p>

<h2>1. Download your X.509 certificates</h2>

<p>Amazon has a pretty good <a href="http://docs.aws.amazon.com/AmazonDevPay/latest/DevPayDeveloperGuide/X509Certificates.html">checklist</a> for how to do this. You need X.509 certificates so only you and Amazon can access your AMI, which for most layers is a sensible security precaution. For this walkthrough I&rsquo;ll assume you have the private key downloaded to ~/certs/pk-X509.pem and the the certificate downloaded to ~/certs/cert-X509.pem.</p>

<h2>2. Transfer your certs to the server</h2>

<p>On the server itself:</p>

<p><code>bash
mkdir -p /tmp/cert/
</code></p>

<p>On your local computer:</p>

<p><code>
scp ~/certs/pk-X509.pem ~/certs/cert-X509.pem your-user@your-servers-public-dns:/tmp/cert/
</code></p>

<p>This will securely transfer your certs up to the server. Make sure to replace <code>your-user</code> with whatever user on OpsWorks you have permission to access, and <code>your-servers-public-dns</code> with the public DNS record for your server.</p>

<h2>3. Download the EC2 AMI tools</h2>

<p>I&rsquo;m not totally sure why the AMI tools and API tools are separate packages, but since they are you&rsquo;ll need to install them individually. For the AMI tools:</p>

<p><code>bash
sudo apt-get install -y unzip
wget http://s3.amazonaws.com/ec2-downloads/ec2-ami-tools.zip
sudo mkdir -p /usr/local/ec2
sudo unzip ec2-ami-tools.zip -d /usr/local/ec2
export EC2_AMITOOL_HOME=/usr/local/ec2/ec2-ami-tools-1.5.3/
export PATH=$EC2_AMITOOL_HOME/bin:$PATH
</code></p>

<p>If you got a different version of the AMI tools than 1.5.3, you&rsquo;ll want to replace the AMI tools directory with the proper version.</p>

<h2>4. Download the EC2 API tools</h2>

<p>A similar process to step 3.</p>

<p><code>bash
wget http://s3.amazonaws.com/ec2-downloads/ec2-api-tools.zip
sudo unzip ec2-api-tools.zip -d /usr/local/ec2
sudo apt-get install -y openjdk-7-jre
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/jre/
export EC2_HOME=/usr/local/ec2/ec2-api-tools-1.6.13.0/
export PATH=$PATH:$EC2_HOME/bin
export AWS_ACCESS_KEY=YourAccessKey
export AWS_SECRET_KEY=YourSecretKey
</code></p>

<p>Again, if you downloaded a different version of the API tools, you&rsquo;ll need to change the API tools directory. Also replace <code>YourAccessKey</code> and <code>YourSecretKey</code> with your real access and secret keys.</p>

<h2>5. Ensure your version of GRUB is correct</h2>

<p>On Ubuntu 12.04, I didn&rsquo;t have to do anything except this:</p>

<p><code>bash
sudo apt-get install -y grub gdisk kpartx
</code></p>

<p>But if your image has boot problems GRUB is the most likely culprit. Amazon has a <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami-instance-store.html">good walkthrough</a> of how to set up legacy GRUB properly &mdash; following it should correct any boot issues you experience on your AMI.</p>

<h2>6. Stop all services</h2>

<p>Make sure everything and anything is stopped on the target server. A non-exclusive list:</p>

<p><code>bash
sudo service monit stop
sudo service mysql stop
sudo service nginx stop
sudo service redis stop
sudo service memcached stop
sudo service opsworks-agent stop
</code></p>

<p>Running services can destroy the integrity of the image. Make sure everything is stopped before you waste your time!</p>

<h2>7. Remove instance configuration directories</h2>

<p>All of the instance-specific config directories must be destroyed, or OpsWorks will fail to provision the new image.</p>

<p>```bash
sudo rm -rf /etc/aws/opsworks/ \</p>

<pre><code>        /opt/aws/opsworks/ \
        /var/log/aws/opsworks/ \
        /var/lib/aws/opsworks/ \
        /etc/monit.d/opsworks-agent.monitrc \
        /etc/monit/conf.d/opsworks-agent.monitrc \
        /var/lib/cloud/
</code></pre>

<p>```</p>

<h2>8. Bundle the volume</h2>

<p>Finally, after all that setup, you&rsquo;re ready to actually bundle the volume.</p>

<p>```bash
ec2-bundle-vol -k /tmp/cert/pk-X509.pem \</p>

<pre><code>           -c /tmp/cert/cert-X509.pem \
           -u 123456789012 \
           -r x86_64 \
           -e /tmp/cert \
           -i $(find /etc /usr /opt -name '*.pem' -o -name '*.crt' -o -name '*.gpg' | tr '\n' ',')
</code></pre>

<p>```</p>

<p>Note that we provide the certificate locations as part of this command, so if your certs are named differently change that name above. Also you need to provide the account ID number for the -u flag. You can find this on your <a href="https://console.aws.amazon.com/iam/home?#security_credential">security credentials IAM page</a>, or if you need more help, check out Amazon&rsquo;s <a href="http://docs.aws.amazon.com/general/latest/gr/acct-identifiers.html">documentation on finding your account ID number</a>.</p>

<p>This command will probably take a long while to run.</p>

<h2>9. Create and upload the volume to an S3 bucket</h2>

<p>Once the volume is bundled, go to S3 and create a bucket to receive the machine image. Then run this command on your instance:</p>

<p>```bash
ec2-upload-bundle -b bucket_name/image_name \</p>

<pre><code>              -m /tmp/image.manifest.xml \
              --region us-east-1
</code></pre>

<p>```</p>

<p>Replace <code>bucket_name</code> and <code>image_name</code> with the bucket you created in S3 and whatever you&rsquo;d like to name the image, and the region with whatever region your bucket is located in (and where you want the AMI to be registered). This will also take awhile to run.</p>

<h2>10. Register the AMI</h2>

<p>Only one step left, and this is an easy one! You can register the AMI with this command:</p>

<p><code>bash
ec2-register bucket_name/image_name/image.manifest.xml -n image_name --region us-east-1
</code></p>

<p>You should now successfully see your new image in your list of registered AMIs for your region. Change your layer settings to use a custom image and select the AMI as the image for a new instance and try it out. Hopefully you&rsquo;ll have just cut out a fair amount of time from your instance provisioning process.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Helper Methods in Sprinkle]]></title>
    <link href="http://joshsymonds.com/blog/2013/10/14/helper-methods-in-sprinkle/"/>
    <updated>2013-10-14T16:03:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2013/10/14/helper-methods-in-sprinkle</id>
    <content type="html"><![CDATA[<p>Recently I&rsquo;ve been using <a href="https://github.com/sprinkle-tool/sprinkle">sprinkle</a> a lot in a large client project. Sprinkle is server provisioning software, akin to <a href="http://www.opscode.com/chef/">Chef</a> except much lighter. It&rsquo;s most directly akin to <a href="https://github.com/rubber/rubber">rubber</a>, but rubber&rsquo;s biggest advantage is its pre-built recipes: it&rsquo;s a little finicky to sensibly extend, and those only work well on EC2. Sprinkle is built for extension, customizability, and platform agnosticism, but comes with no recipes at all by default. Tradeoffs!</p>

<p>Sprinkle (and rubber) are very different from most other server provisioning software I&rsquo;ve used &mdash; on the one hand, by leveraging Capistrano for server communication (or SSH or Vlad if you prefer), it remains extremely light and focused on just provisioning. But on the other, it inherits most of Capistrano&rsquo;s downsides too: primary among them is that it&rsquo;s easy to repeat yourself if you&rsquo;re not careful. So I wanted to post a quick tip for other people using sprinkle on how to DRY it up just a little bit.</p>

<!-- more -->


<p>Let&rsquo;s say you have a helper method you want to include in all policies, packages, and verifiers. Make a module to contain it, something like this:</p>

<p>```ruby</p>

<h1>sprinkle/config/helpers.rb</h1>

<p>module Sprinkle
  module Helpers</p>

<pre><code>def templates
  path = File.expand_path('../../', __FILE__)
  "#{path}/templates" # sprinkle/templates/
end
</code></pre>

<p>  end
end
```</p>

<p>The problem is that to use this helper method in a lot of different places requires a little bit of work. You can&rsquo;t just do something like this:</p>

<p>```ruby</p>

<h1>sprinkle/policies/base.rb</h1>

<p>policy :base, roles: :web do
  requires :build_essential if File.exists?(&ldquo;#{templates}/build_essential.txt&rdquo;)</p>

<pre><code>                                         # No method error for templates
</code></pre>

<p>end</p>

<p>package :build_essential do
  file &ldquo;/etc/build_essential.txt&rdquo;,</p>

<pre><code>contents: render("#{templates}/build_essential.txt"), # No method error for templates
sudo: true
</code></pre>

<p>  verify do</p>

<pre><code>has_file "/etc/build_essential.txt"
puts "#{templates}/build_essential.txt" # Contrived example since you'd never really
                                        # just puts something here, but this also
                                        # throws a no method error
</code></pre>

<p>  end
end
```</p>

<p>You need to include the <code>Helpers</code> module in each class: policy, packages, and verifiers. That&rsquo;s easy enough to do. After you define your helper, do something like this:</p>

<p>```ruby</p>

<h1>sprinkle/config/helpers.rb</h1>

<p>class Sprinkle::Policy
  include Sprinkle::Helpers
end</p>

<p>module Sprinkle::Package
  class Package</p>

<pre><code>include Sprinkle::Helpers
</code></pre>

<p>  end
end</p>

<p>module Sprinkle
  class Verify</p>

<pre><code>include Sprinkle::Helpers
</code></pre>

<p>  end
end
```</p>

<p>Now your helpers will be available everywhere you expect, allowing you to use them anywhere but still define them in one place.</p>

<p>I&rsquo;ll post some more neat sprinkle tidbits in the future, but this by itself allowed me to significantly dry up my code and enjoy my sprinkle experience quite a lot more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pricing Popular Hosting Options (With Devops Time)]]></title>
    <link href="http://joshsymonds.com/blog/2013/04/17/pricing-popular-hosting-options-with-devops-time/"/>
    <updated>2013-04-17T18:16:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2013/04/17/pricing-popular-hosting-options-with-devops-time</id>
    <content type="html"><![CDATA[<p>Recently I compared the major Rails hosting providers &mdash; but as opposed to most price breakdowns I&rsquo;ve read on the Internet, I opted to include provisional hourly devops time to set up and perform maintenance on the servers. For the purposes of this comparison, I only selected four providers: AWS, RackSpace, BlueBox and Heroku, and I&rsquo;m assuming you use all their services (rather than combining two, say Heroku Postgres with AWS EC2 instances). I found the resulting price breakdown instructive, though interpreting them (and disagreeing with the provided hours) are left as an exercise for the reader.</p>

<!-- more -->


<h2>Comparisons</h2>

<p>Any of these configurations should be adequate to support roughly a million requests a month (assuming throughput of 5 requests a second), provided most of the requests served aren&rsquo;t that complicated. We&rsquo;ll go for a medium database instance and aggressively cache as much as possible, thus we&rsquo;ll also need to provide memcached room somewhere.</p>

<p>The big differentiator in my comparison (as opposed to others') is certainly a devops contractor at $150 an hour. I&rsquo;ll include the hours as I would estimate them personally, but for other people it might take longer or shorter &mdash; and the price could go up if there&rsquo;s a ton of other software to go in the server. (For example, this theoretical application would probably eventually want redis and some sort of asynchronous worker system.)</p>

<p>So let&rsquo;s get down to the details!</p>

<h3>Amazon Web Services</h3>

<table class='numbers'>
  <tr>
    <th style='width: 72%;'>Service</th>
    <th>Setup</th>
    <th>Monthly</th>
  </tr>
  <tr>
    <td>
      <h4>1 medium EC2 instance (1 year contract, medium utilization)</h4>
      6 unicorn workers<br/>
      1 nginx reverse proxy<br/>
      memcached
    </td>
    <td>$277.00</td>
    <td>$30.74</td>
  </tr>
  <tr>
    <td>
      <h4>1 medium RDS instance (1 year contract, medium utilization)</h4>
    </td>
    <td>$500.00</td>
    <td>$40.26</td>
  </tr>
  <tr>
    <td>
      <h4>Devops Time</h4>
      10 hours setup<br />
      5 hours maintenance
    </td>
    <td>$1500.00</td>
    <td>$750.00</td>
  </tr>
  <tr class='highlighted'>
    <th>Total</th>
    <th>$2277.00</th>
    <th>$821.00</th>
  </tr>
  <tr class='highlighted'>
    <th>First Year</th>
    <th colspan='2'>$12129.00</th>
  </tr>
</table>


<p>No surprises here: if you&rsquo;re using AWS, the hardware is ridiculously cheap. Most of your cost is going to be engineering time to get the instance up and running and then perform maintenance and add additional features to it. That said, I&rsquo;ve had an EC2 instance going for about 8 months now with no maintenance at all on my part (laziness!), so if you don&rsquo;t need any additional server setup you can probably omit the maintenance time, for a monthly cost of $71.00 and a yearly cost of $3129.00.</p>

<h3>RackSpace</h3>

<table class='numbers'>
  <tr>
    <th style='width: 72%;'>Service</th>
    <th>Setup</th>
    <th>Monthly</th>
  </tr>
  <tr>
    <td>
      <h4>1 4GB managed cloud instance</h4>
      6 unicorn workers<br/>
      1 nginx reverse proxy<br/>
      memcached
    </td>
    <td>$0.00</td>
    <td>$262.80</td>
  </tr>
  <tr>
    <td>
      <h4>1 4GB cloud database instance</h4>
    </td>
    <td>$0.00</td>
    <td>$321.20</td>
  </tr>
  <tr>
    <td>
      <h4>Devops Time</h4>
      10 hours setup<br />
      2 hours maintenance
    </td>
    <td>$750.00</td>
    <td>$300.00</td>
  </tr>
  <tr class='highlighted'>
    <th>Total</th>
    <th>$750.00</th>
    <th>$884.00</th>
  </tr>
  <tr class='highlighted'>
    <th>First Year</th>
    <th colspan='2'>$11358.00</th>
  </tr>
</table>


<p>RackSpace&rsquo;s managed cloud offerings are more expensive than AWS, but the theory is you can omit server-related maintenance (since they&rsquo;ll keep services running and your servers themselves operational) and that&rsquo;s reflected in a lowered monthly devops cost. They don&rsquo;t do maintenance or improvements on your application proper, however, so I built a rather modest two hours a month in for simple tasks like upgrading Rails or performing minor server optimizations. You can once again probably ignore the monthly devops cost if you like, but that won&rsquo;t have nearly the impact on the final price that it did for AWS, with a new monthly of $584.00 and a final year total of $7758.00.</p>

<h3>BlueBox</h3>

<table class='numbers'>
  <tr>
    <th style='width: 72%;'>Service</th>
    <th>Setup</th>
    <th>Monthly</th>
  </tr>
  <tr>
    <td>
      <h4>1 4GB cloud instance</h4>
      6 unicorn workers<br/>
      1 nginx reverse proxy<br/>
      memcached
    </td>
    <td>$0.00</td>
    <td>$385.00</td>
  </tr>
  <tr>
    <td>
      <h4>1 4GB cloud database instance</h4>
    </td>
    <td>$0.00</td>
    <td>$385.00</td>
  </tr>
  <tr>
    <td>
      <h4>Devops Time</h4>
      0 hours setup<br />
      0 hours maintenance
    </td>
    <td>$0.00</td>
    <td>$0.00</td>
  </tr>
  <tr class='highlighted'>
    <th>Total</th>
    <th>$0.00</th>
    <th>$770.00</th>
  </tr>
  <tr class='highlighted'>
    <th>First Year</th>
    <th colspan='2'>$9240.00</th>
  </tr>
</table>


<p>BlueBox&rsquo;s claim to fame is that they perform server, application, and database setup, maintenance, and integration. Thus the need for a devops engineer is completely obviated (as reflected in the final totals). Obviously this price point is extremely attractive if you&rsquo;d otherwise have to pay a server administrator and engineer, but if you have one on staff already then BlueBox&rsquo;s product is easily the most expensive. You&rsquo;re paying for their expertise much more than their hardware.</p>

<h3>Heroku</h3>

<table class='numbers'>
  <tr>
    <th style='width: 72%;'>Service</th>
    <th>Setup</th>
    <th>Monthly</th>
  </tr>
  <tr>
    <td>
      <h4>4 dynos</h4>
      12 unicorn workers<br/>
    </td>
    <td>$0.00</td>
    <td>$143.00</td>
  </tr>
  <tr>
    <td>
      <h4>memcached addon (500 MB)</h4>
    </td>
    <td>$0.00</td>
    <td>$40.00</td>
  </tr>
  <tr>
    <td><h4>Fugu database instance</h4></td>
    <td>$0.00</td>
    <td>$400.00</td>
  </tr>
  <tr>
    <td>
      <h4>Devops Time</h4>
      2 hours setup<br />
      0 hours maintenance
    </td>
    <td>$300.00</td>
    <td>$0.00</td>
  </tr>
    <tr class='highlighted'>
    <th>Total</th>
    <th>$300.00</th>
    <th>$583.00</th>
  </tr>
  <tr class='highlighted'>
    <th>First Year</th>
    <th colspan='2'>$7296.00</th>
  </tr>
</table>


<p>I&rsquo;m always somewhat mystified by Heroku&rsquo;s pricing &mdash; their database offerings are incredibly expensive, especially compared to their incredibly cheap dynos. Anyway, they provide the least expensive option for purely hosting an application, but this cheapness comes with a hidden price. Being unable to control your production environment can be a frightening proposition and exposes you to potential hidden vagaries of Heroku&rsquo;s internals (such as the latest flap about their routing mesh). And the fact that their addons are third-party products means that if they go down, you have no ability to expedite their repair. I would deploy a small or medium app to Heroku (which might be perfect for this theoretical application), but for a bigger one I would definitely be hesitant.</p>

<h2>Conclusions</h2>

<p>I don&rsquo;t think any of these prices are particularly surprising. For knowledgeable server engineers, AWS is indeed a tremendous bargain. For those with little or no infrastructure knowledge, Heroku or BlueBox would be a much better choice. And keep in mind these are the hours it would take me to set up these instances; the times might not be representative of another engineer. I think they&rsquo;re reasonable though, and that the comparison is an interesting one to draw, even if not a tremendous revelation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why I Chose Chef Over Rubber]]></title>
    <link href="http://joshsymonds.com/blog/2013/01/18/why-i-chose-chef-over-rubber/"/>
    <updated>2013-01-18T14:34:00-06:00</updated>
    <id>http://joshsymonds.com/blog/2013/01/18/why-i-chose-chef-over-rubber</id>
    <content type="html"><![CDATA[<p>One of my mandates at Everest has been to sanitize the server build and deploy process. Provisioning every server individually with the same bash script was not exactly the height of extensibility and maintainability, and unfortunately had resulted in an enormous cluster that was very opaque: there was nearly no visibility into what the servers were actually doing. When I evaluated options to create a better process I looked at my go-to configuration management tool, <a href="https://github.com/wr0ngway/rubber">rubber</a>, in addition to <a href="http://en.wikipedia.org/wiki/Chef_(software)">Chef</a> and <a href="http://en.wikipedia.org/wiki/Puppet_(software)">Puppet</a>. As a result of this evaluation &mdash; and surprising even myself &mdash; I ended up choosing Chef as our solution. Here&rsquo;s why.</p>

<!-- more -->


<h2>Collaboration</h2>

<p>One of rubber&rsquo;s weaknesses is it is not a particularly great collaborative tool. If both you and someone else are provisioning a new server simultaneously, you&rsquo;ll get a merge conflict in your server yaml file: you really don&rsquo;t want to make a mistake resolving <em>that</em> merge conflict.</p>

<p>By contrast, it&rsquo;s really easy for multiple people to work together in Chef. You can be working in the same cookbook, even, and just altering different recipes. Bootstrapping several servers simultaneously couldn&rsquo;t be easier. And treating the Chef server as the central authority for cookbooks is also extremely helpful for keeping everyone on the same page with regards to what&rsquo;s actually going into the servers.</p>

<p>Chef is just a better tool for teams of people.</p>

<h2>Extensibility &amp; Community Support</h2>

<p>For the tools that rubber provides in its stack &mdash; and it provides a lot &mdash; it&rsquo;s an excellent solution. But adding additional facilities into rubber is a pain. You either have to come up with recipes on your own, or hope that someone has a semi-active fork with what you want in it. There&rsquo;s no real extensibility, and while it&rsquo;s easy enough to roll your own recipes, it&rsquo;d definitely be ideal not to repeat work if you&rsquo;re fairly confident someone else has already done it.</p>

<p>Enter Chef cookbooks. There are a frightening amount of active cookbooks on Github for every need imaginable. Many are actively supported, and even if they&rsquo;re not precisely what you&rsquo;re looking for, they provide an excellent jumping-off point for creating your own solutions.</p>

<p>We&rsquo;re using the excellent <a href="https://github.com/applicationsonline/librarian">librarian</a> gem to manage our external cookbooks and the source cookbooks I&rsquo;ve been developing internally for us. It&rsquo;s a great way to treat cookbooks like any other dependency to resolve, and will save you a lot of time in git cloning repositories.</p>

<h2>More Granularity</h2>

<p>rubber allows you to control a lot, on a per-server basis. But it has no real equivalent to data bags or even environments. Adding a user&rsquo;s SSH key to my deploy recipe used to be an unpleasant process. Now I can just update the users data bag with a new entry and instruct my servers to pull it: tada, new user on the servers.</p>

<p>Similarly changing postfix configuration on a per-environment basis is a snap.</p>

<h1>But Rubber is a Great Tool</h1>

<p>Don&rsquo;t get me wrong: I still really like rubber. It doesn&rsquo;t fit for Everest&rsquo;s use case, definitely &mdash; with so many servers and so much going on behind the scenes, we really needed more granularity, control, and power. But if I were provisioning just one server, or even three or four, then rubber would still be my go-to tool.</p>

<p>Why? It&rsquo;s just a whole lot faster to get started with than Chef. It makes tons of sensible default decisions that simplify your life really significantly. You don&rsquo;t have to go searching for good recipes or the right way to do things. Just like Rails, rubber <strong>knows</strong> the right way to do things. As long as you take its advice you&rsquo;ll go far, but trying to work against its defaults will be really painful.</p>

<h2>Final Word on Chef vs. Puppet</h2>

<p>Doesn&rsquo;t matter, choose whichever you like more.</p>
]]></content>
  </entry>
  
</feed>
