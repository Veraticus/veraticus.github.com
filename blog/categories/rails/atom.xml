<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | Josh Symonds]]></title>
  <link href="http://joshsymonds.com/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://joshsymonds.com/"/>
  <updated>2012-03-26T01:06:16-05:00</updated>
  <id>http://joshsymonds.com/</id>
  <author>
    <name><![CDATA[Josh Symonds]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Elasticsearch and Percolation in Rails]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails/"/>
    <updated>2012-03-25T11:39:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/25/elasticsearch-and-percolation-in-rails</id>
    <content type="html"><![CDATA[<p>Hipstamatic uses the pretty awesome Family Album feature for people to like and react to each others' photos. You can create either a magic album -- an album that matches to a combination of criteria including accounts, geolocation, tags and descriptions -- or a curated album, selecting photos directly that you want to include. The latter is a pretty straight-forward association and isn't very interesting to talk about, but I wanted to discuss briefly the methods we used to implement magic albums and what we finally settled on. It involved a lot of setting up elasticsearch and percolation, and ultimately I think it's a very durable, excellent solution for anyone wanting to index a lot of data and retrieve it extremely quickly.</p>

<!-- more -->


<p>Initially, magic albums were a set of complicated MySQL queries. I think anyone who's had experience with indexes in an enormous MySQL database knows where this one is going... its performance was terrible, and as more people created more albums our RDS instance started really chugging. The worst part was we were spending enormous amounts of time, energy, and money invested in a small part of our application, and it was having a cascade effect through the database ruining the rest of the user experience.</p>

<p>As a stopgap measure, we switched to using Redis lists to hold the association but kept the actual index in MySQL. Recently though we migrated away from MySQL completely to an index storage called <a href="http://www.elasticsearch.org/">elasticsearch</a>. Elasticsearch is awesome because it's built on Lucene, is incredibly easy to get going, and is very very powerful. I passed over search solutions like <a href="http://sphinxsearch.com/">Sphinx</a> and <a href="http://www.searchify.com/">Searchify</a> mostly because we aren't doing any text searching: all of the queries albums perform on photos are controlled by direct, matched fields. We just needed a great, simple engine for indexing them constantly and pulling results out quickly -- an engine that wouldn't bring the rest of our stack down if there was an indexing failure or if we were bombarded with many simultaneous queries.</p>

<p>Elasticsearch has given us all that and more. Using the amazing <a href="https://github.com/karmi/tire">tire</a> gem, it was simple to get our photo model set up correctly:</p>

<p>```ruby
class Photo &lt; ActiveRecord::Base
  include Tire::Model::Search</p>

<p>  mapping do</p>

<pre><code>indexes :id
indexes :lat_lng, :type =&gt; :geo_point
indexes :account_id
indexes :created_at, :type =&gt; :date
indexes :tags
</code></pre>

<p>  end
end
```</p>

<p>(The code here is changed slightly from its production form to redact business logic and simplify it.) Of course, the real magic takes place in the albums model. Albums are essentially saved queries, if you think about it: they should search for photos every time they're called. So we have a method to generate the query we're looking for:</p>

<p>```ruby
class Album &lt; ActiveRecord::Base</p>

<p>  def elasticsearch_query</p>

<pre><code>query = []
query &lt;&lt; {:terms =&gt; {:account_ids =&gt; query[:accounts]}} unless query[:accounts].blank?
query &lt;&lt; {:terms =&gt; {:tags =&gt; query[:tags]}} unless query[:tags].blank?
query &lt;&lt; {:range =&gt; {:created_at =&gt; {:from =&gt; query[:starts_at], :to =&gt; query[:ends_at]}}} unless query[:starts_at].blank? &amp;&amp; query[:ends_at].blank?
query &lt;&lt; {:geo_distance =&gt; {:lat_lng =&gt; [query[:lat].to_f, query[:lng].to_f.join(','), :distance =&gt; "#{query[:range]}km"}} unless query[:lat].blank? || query[:lng].blank?
query
</code></pre>

<p>  end</p>

<p>end
```ruby</p>

<p>These are all, in elasticsearch parlance, filters rather than queries: queries must look into data fields and perform operations in them, whereas filters just filter on a fields' value directly... exactly what I was looking for. <code>terms</code> instructs the filter parser that at least one of the select elements must match. <code>range</code>, as you can see, allows us to pull only photos within a certain date. <code>geo_distance</code> is particularly cool and lets us filter all photos by their geographic location.</p>

<p>Using this couldn't be simpler:</p>

<p>```ruby
class Album &lt; ActiveRecord::Base</p>

<p>  def elasticsearch_photos</p>

<pre><code>finder = Photo.search do
  query { all }
  filter(:and, elasticsearch_query) unless elasticsearch_query.empty?
  sort {by :created_at, "desc" }
end

finder.results
</code></pre>

<p>  end
```</p>

<p>Tada! Easy and simple searching inside your models. The performance gain for us was massive; elasticsearch has a ridiculously small memory footprint, but consistently returns responses to us in 50-60 milliseconds. Now that's performance!</p>

<p>Many of you might be wondering, though, how we get the reverse of this association. Albums have many (searched) photos; how does a photo know what album it's in? This was a stumbling block for the other search solutions I investigated, and I was concerned I would have to bust out the old, gimpy MySQL.</p>

<p>But elasticsearch to the rescue! It employs a very neat feature called <a href="http://www.elasticsearch.org/blog/2011/02/08/percolator.html">the percolator</a>. Percolation allows us to save searches as an index themselves, and then determine what objects match any of the saved searches. So, we save the search an album would conduct along with the album's ID into the photo percolator; then we can determine what queries a photo matches when we save it. It's really quite ingenuous and was, of course, ridiculously easy to set up:</p>

<p>```
class Album &lt; ActiveRecord::Base
  after_save :register_query</p>

<p>  def register_query</p>

<pre><code>Photo.index.register_percolator_query(self.id) do |q|
  q.filtered do
    query {all}
    filter(:and, elasticsearch_query) unless elasticsearch_query.empty?
  end
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>This uses the same <code>elasticsearch_query</code> method as above (of course, since we want to save the same query into the database). And on the photo model, to use it, we just do:</p>

<p>```
class Photo &lt; ActiveRecord::Base</p>

<p>  def percolated_albums</p>

<pre><code>Album.find(Photo.index.percolate(self))
</code></pre>

<p>  end
end
```</p>

<p>This was a rather whirlwind tour, but I was really impressed at how easy it was to get elasticsearch set up properly. It really has added quite a lot to our stack and I look forward to using it on other domain problems (maybe even including full text search)! It was pretty easy to get it tested as well, but I think I'll save details on how I did that for another post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sweeping Caches from Resque (or Anywhere Really)]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/19/sweeping-caches-from-resque-or-anywhere-really/"/>
    <updated>2012-03-19T10:29:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/19/sweeping-caches-from-resque-or-anywhere-really</id>
    <content type="html"><![CDATA[<p>Phil Karlton, someone I can only presume is a pretty smart programmer, said <a href="http://martinfowler.com/bliki/TwoHardThings.html">"there are only two hard things in Computer Science: cache invalidation and naming things."</a> He's totally right; cache invalidation is one of the biggest headaches when designing highly usable, highly available websites and is something that I'm sure every Rails programmer worth their salt has struggled with. (Naming things is also a pain but not the focus of this post.)</p>

<!-- more -->


<p>And unfortunately the reason for the struggle is that Rails' caching tools don't go nearly as far as they should. This is really through no fault of their own; honestly, Rails' caching methods are amazingly robust, and if you don't know what they are, you should read <a href="http://guides.rubyonrails.org/caching_with_rails.html">the guide</a> on them. But good tools can only take you so far. Ultimately, caching is as application-specific as you can get, and when you get to finely-grained control you have to take the reins yourself.</p>

<p>One of the problems I ran into recently was invalidating caches during an association join. I have two models, album and photo, and when one is added to the other I wanted to expire all the caches dealing with both. I already have <a href="http://api.rubyonrails.org/classes/ActionController/Caching/Sweeping.html">cache sweepers</a> in my application, but callbacks aren't triggered on association. And putting something in an after_add on the association itself didn't seem like the right answer; why should I put cache expiration stuff in my model when I already have sweepers dedicated to that logic?</p>

<p>I'm not sure I'm in love with the solution I came up with, but it certainly seems to work. All of the association logic happens in Resque jobs, so I added the cache invalidation directly to this jobs by invoking the sweeper manually:</p>

<p><code>ruby
PhotoSweeper.send(:new).expire_cache_for(photo)
</code></p>

<p>The <code>send</code> business is necessary because new is a private method for sweepers. Nevertheless this really seems to get the job done; the caches are swept appropriately, and my cache invalidation logic remains safely in the sweepers, where I can add or edit it as much as I want. I suppose if I really wanted to I could put this in an after_add on the model as well. I've resisted that so far but maybe it's the logical place for this kind of expiration logic to happen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fnordmetric: Native Rails Metrics]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/13/fnordmetric-native-rails-metrics/"/>
    <updated>2012-03-13T22:05:00-05:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/13/fnordmetric-native-rails-metrics</id>
    <content type="html"><![CDATA[<p>Over the weekend I spent some time getting <a href="https://github.com/paulasmuth/fnordmetric">Fnordmetric</a> set up in an application. On the surface it looks really cool and quite nifty, but I ran into some trouble getting it configured how I wanted it and figured I'd make a post about it. I think I might have been struggling against the conventions in it a little too much, but it was still an instructive battle.</p>

<!-- more -->


<h2>Engineize It</h2>

<p>The Gem itself assumes you'll be running it on its own port, presumably redirecting nginx traffic there. But this is 2012 and Rails engines are all the rage -- so why bother with a separate app? Well, I'll get to the reason why later, but mounting it as an engine is pretty simple.</p>

<p>Set up an initializer or something that defines all the Fnord metrics you want, something like <code>config/initializers/fnord.rb</code>
```ruby
require "fnordmetric"</p>

<p>FnordMetric.namespace :analytics do
  gauge :events_total,</p>

<pre><code>:tick =&gt; 1.day.to_i, 
:progressive =&gt; true,
:title =&gt; "Events (total)"
</code></pre>

<p>  event(:"*") do</p>

<pre><code>incr :events_tota
</code></pre>

<p>  end
end</p>

<p>FnordMetric.server_configuration = {
  :redis_url => "redis://localhost:6379",
  :redis_prefix => "fnordmetric",
  :inbound_stream => ["0.0.0.0", "1339"],
  :start_worker => true,
  :print_stats => 3,
  :event_queue_ttl => 120,
  :event_data_ttl => 3600<em>24</em>30,
  :session_data_ttl => 3600<em>24</em>30
}
```</p>

<p>That stuff is copy-pasted from the Github README, so I won't go into explaining it. Note that we do not include FnordMetric.standalone at the bottom, however; we'll be mounting the server ourselves in routes.rb like so:</p>

<p><code>ruby
  mount FnordMetric.embedded, :at =&gt; "/fnord"
</code></p>

<p>Then you can go to localhost:3000/fnord, and tada! Fnord metrics!</p>

<h2>Set Up a Worker</h2>

<p>The difficult, of course, is that each instance of your app will now also spin up its own instance of a FnordWorker, which might not be what you want. I got around this by altering my config/initializers/fnord.rb:</p>

<p><code>ruby
FnordMetric.server_configuration = {
  :redis_url =&gt; "redis://localhost:6379",
  :redis_prefix =&gt; "fnordmetric",
  :inbound_stream =&gt; ["0.0.0.0", "1339"],
  :start_worker =&gt; (Rails.env.development? || ENV['FNORD_WORKER'] ? true : false),
  :print_stats =&gt; 3,
  :event_queue_ttl =&gt; 120,
  :event_data_ttl =&gt; 3600*24*30,
  :session_data_ttl =&gt; 3600*24*30
}
</code></p>

<p>I know some people hate the ternary operator, but I kind of like it. Anyway, this causes the worker to start only if there's an environment variable set to start it or the Rails environment is development. I set up one instance that receives this variable when it starts, and now I only have one worker. Simplicity itself!</p>

<p>Ultimately, I like Fnordmetric, but I'm not using it in my production applications. I feel like there's a level of abstraction to go before it's really usable in big production apps. It's much better at tracking arbitrary metrics than NewRelic -- honestly, trying to shoehorn stats into their system feels silly at times -- but setting up the tracking stuff is a pain, involving a lot of unnecessary repetition. I think that a Fnordmetric2.0 would be awesome, though, so I hope the project sees more love and work. And who knows, if I have some time I'll try contributing to it myself. That's the joy of open source: if you have a good idea, you make it happen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails 3: Arel, Arel_Table, and Squeel]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/10/rails-3-arel%2Carel_table%2C-and-squeel/"/>
    <updated>2012-03-10T10:17:00-06:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/10/rails-3-arel,arel_table,-and-squeel</id>
    <content type="html"><![CDATA[<p>Rails 3 provides a lot of really neat functionality, and one of the pieces that looked coolest was Arel -- ActiveRecord's own relational algebra. Finally, we could get rid of SQL in queries and use a clear, syntactic DSL to manage our queries!</p>

<p>Well, in reality, that isn't quite what happened. ActiveRecord's Arel functionality does provide some neat criteria chaining methods, but unfortunately you either end of typing a lot of raw SQL:</p>

<!-- more -->


<p><code>ruby
Model.select("sum(model.column) as 'model_sum'").order("created_at
DESC").where("models.created_at &gt; ?", DateTime.now - 1.day)
</code></p>

<p>Or using unpleasant workarounds to address the underlying Arel for the model:</p>

<p><code>ruby
Model.where(Model.arel_table[:title].matches('%foo%'))
</code></p>

<p>This is just kinda ugly. Happily, there's a Gem that addresses this problem called <a href="https://github.com/ernie/squeel">squeel</a> that makes Arel what, in my mind, it should be. It provides an elegant, simple syntax for creating and managing queries that is sensibly divorced both from the underlying Arel and raw SQL of the database:</p>

<p><code>ruby
Model.where
</code></p>

<p>Much easier to understand! The double-curly braces does kind of suck (this is because it's a hash inside a proc) but it's still a fair but more understandable than the default Arel stuff.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Don't Mess With Primary Keys]]></title>
    <link href="http://joshsymonds.com/blog/2012/03/04/dont-mess-with-primary-keys/"/>
    <updated>2012-03-04T19:11:00-06:00</updated>
    <id>http://joshsymonds.com/blog/2012/03/04/dont-mess-with-primary-keys</id>
    <content type="html"><![CDATA[<p><a href="http://stackoverflow.com/users/1224374/veraticus">I really like answering questions on Stack Overflow</a> -- it's like a trivia game that you win by knowing Rails backwards and forwards, but instead of cheesy prizes you get awesome reputation points! And also little badges!</p>

<p>Recently I've been seeing a lot of beginner-style questions, and the most popular has definitely been some variant of "how do I mess with the primary key column?"</p>

<p>The answer is always, invariably, the same: don't.</p>

<!-- more -->


<p>It might seem sensible to tuck some sort of business logic away into your primary key. Just earlier today, <a href="http://stackoverflow.com/questions/9558715/changing-models-id-type-from-integer-to-decimal-makes-all-entries-try-to-be-0-0/9558832#9558832">I answered a question</a> from a guy who wanted to turn his primary key column into a decimal, and have the part before the decimal be equal to the primary key of another table -- so you'd have 75.001 and 75.002, with 75 being the primary key of the orders table. A cute idea for a new column like order_number or something like that, but just a plain awful idea for a primary key.</p>

<p>Primary keys, when you get right down to it, are database artifacts. They're useful because they allow databases to expose powerful relations for our data: without a way for databases to reference individual rows that are guaranteed to be unique, even the most basic joins would be impossible. And because they're important for databases, the assumption seems to be that they're important for people too.</p>

<p>Part of this is Rails' fault. By exposing URLs with primary keys by default (like users/4), one would automatically assume that the primary key is important data for a user to know (your key is 4 and that's important!). In reality nothing could be further from the truth: the ID for a user is arbitrary database-internal logic and has no business facing users at all. I wish Rails going forward came bundled with the really awesome <a href="https://github.com/norman/friendly_id">FriendlyId</a> Gem that makes some unique database column appear to your internal application logic as the real ID for that table. Then you'd have URLs like users/josh, and that both looks better and obfuscates the primary key.</p>

<p>As a sidenote, this is why UUID-based keys like <a href="http://www.mongodb.org/display/DOCS/Object+IDs">MongoDB's</a> and <a href="https://github.com/Veraticus/Dynamoid">Dynamoid's</a> are rather nifty -- they make really ugly ID-based URLs by default so force you to choose a better column to use as a URL slug.</p>

<p>The problem with all this attention on the primary key is that, invariably, people want to change it. Changing primary keys is awful. It will disassociate data all throughout your database, it messes with table autoincrementing... it will lead to problems right at the moment, and even more down the road you won't even foresee. Or even worse, you'll want to choose something nonstandard as a primary key (or not choose one at all) -- and you'll want to perform a join and be forced to deal with the consequences of your decision. Hint: they won't be pretty.</p>

<p>So do yourself a favor. View the ID column as what it really is: an internal database construction. It should be an auto-incrementing integer, no excuses. If you want any kind of business logic, make a new column for it and manage it separately. You'll be glad you did, I promise.</p>
]]></content>
  </entry>
  
</feed>
